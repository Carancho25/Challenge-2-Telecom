{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPG85TGnt9U/tEngEULgoez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carancho25/Challenge-2-Telecom/blob/main/Informe_Final_de_Telecom_2_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I. Manejo de los Datos**"
      ],
      "metadata": {
        "id": "DruJv1w16kxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "srSDebg-Lhmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **I.1 Extracion y visualizacion de los Datos**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ByxYXG4kO6Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "apZA_L1b1Hie"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos = pd.read_csv(\"datos_limpios.csv\")\n"
      ],
      "metadata": {
        "id": "32Ooy2psvfzr",
        "outputId": "63d5a5bb-aa8c-488b-e730-df74392545c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'datos_limpios.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-487125393.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datos_limpios.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datos_limpios.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos.head(10)\n"
      ],
      "metadata": {
        "id": "z4Ud-FCqwwND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I.2 Tratamiento de Datos**"
      ],
      "metadata": {
        "id": "r6-ROlv0Qum2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eliminacion de Columna Customer Id**"
      ],
      "metadata": {
        "id": "JHFJQ3arPPw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos = datos.drop('customerID', axis=1)\n",
        "display(datos.head(10))"
      ],
      "metadata": {
        "id": "TaMawihPPZh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(datos.isnull().sum())"
      ],
      "metadata": {
        "id": "8F6KiSL8wzaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Se elimina columna CustomerID, que no aporta para el modelo predictivo y se verifican datos nulos\""
      ],
      "metadata": {
        "id": "MM0cu6zNyKiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos.info()"
      ],
      "metadata": {
        "id": "A0RxapO-48Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Identificador de columnas categoricas\""
      ],
      "metadata": {
        "id": "J0xnNc6a1qLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = datos.select_dtypes(include='object').columns\n",
        "print(\"Columnas categóricas identificadas:\")\n",
        "print(categorical_cols)"
      ],
      "metadata": {
        "id": "JO3uu9Jc49xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Eliminamos la variable -1 en Churn_numeric **"
      ],
      "metadata": {
        "id": "blU2SaPvUMe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "datos = datos[datos['Churn_numeric'] != -1].copy()\n",
        "\n",
        "print(\"\\nDimensiones del DataFrame después de eliminar filas con Churn_numeric = -1:\", datos.shape)\n",
        "print(\"Nueva distribución de 'Churn_numeric' (después de eliminar -1):\")\n",
        "print(datos['Churn_numeric'].value_counts())\n",
        "print(\"Porcentaje de cada clase (después de eliminar -1):\")\n",
        "print(datos['Churn_numeric'].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "id": "OlUShNlrUMFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Convertir account.Charges.Total a numérico y manejar valores nulos **"
      ],
      "metadata": {
        "id": "UwUPVEOkVI-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos['account.Charges.Total'] = pd.to_numeric(datos['account.Charges.Total'], errors='coerce')"
      ],
      "metadata": {
        "id": "hBNo41s-VImx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos['account.Charges.Total'].fillna(datos['account.Charges.Total'].mean(), inplace=True)\n",
        "\n",
        "print(\"\\nTipo de dato de 'account.Charges.Total' DESPUÉS de la conversión y manejo de NaN:\", datos['account.Charges.Total'].dtype)\n",
        "print(\"Descripción estadística de 'account.Charges.Total' después de la conversión:\")\n",
        "print(datos['account.Charges.Total'].describe())\n",
        "print(\"\\nInformación general del DataFrame (para ver el tipo de dato de todas las columnas):\")\n",
        "datos.info()"
      ],
      "metadata": {
        "id": "3gat8-POVrLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Verificacion del porcentaje de cancelacion (Churn) **"
      ],
      "metadata": {
        "id": "uHMHhYoU8wet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Mostrar la distribución de la variable 'Churn_numeric, para verificar si hay desbalance **"
      ],
      "metadata": {
        "id": "N5R_HFcd_mhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Distribución de la variable 'Churn_numeric':\")\n",
        "print(datos['Churn_numeric'].value_counts())\n",
        "print(\"\\nPorcentaje de cada clase:\")\n",
        "print(datos['Churn_numeric'].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "id": "beJUKuGm_mMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Eliminacion de la Columna Churn, dado que ya se tiene Churn_numeric para evitar informacion confusa **\n"
      ],
      "metadata": {
        "id": "9ksnk8XYXOSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'Churn' in datos.columns:\n",
        "    datos.drop('Churn', axis=1, inplace=True)\n",
        "    print(\"Columna 'Churn' original (texto) eliminada.\")"
      ],
      "metadata": {
        "id": "j7461DlUXkjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Aplicar One-Hot Encoding a las columnas categóricas restantes\n",
        "**"
      ],
      "metadata": {
        "id": "bljkLuLDX_5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = datos.select_dtypes(include='object').columns\n",
        "\n",
        "print(\"\\nColumnas categóricas identificadas para One-Hot Encoding:\", categorical_cols.tolist())\n",
        "\n",
        "# Aplicamos One-Hot Encoding.\n",
        "# 'drop_first=True' evita la multicolinealidad, eliminando una de las columnas binarias\n",
        "# creadas para cada variable original. Por ejemplo, para 'Gender', si tienes 'Female' y 'Male',\n",
        "# solo se crearía 'Gender_Male' (si es 1, es Male; si es 0, es Female).\n",
        "df_encoded = pd.get_dummies(datos, columns=categorical_cols, drop_first=True)"
      ],
      "metadata": {
        "id": "b2b_rMU9YPoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Analisis de Correlacion: Matriz de Correlacion ##\n"
      ],
      "metadata": {
        "id": "xXqao8HLHm3U"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba3ead00"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "correlation_matrix = df_encoded.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(18, 14))\n",
        "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Relacion de la variable independiente con el resto de variables **"
      ],
      "metadata": {
        "id": "FoLbWNqh-UQt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee4af136"
      },
      "source": [
        "\n",
        "# calculo de la matriz de correlacion #\n",
        "correlation_matrix = df_encoded.corr()\n",
        "\n",
        "churn_correlations = correlation_matrix['Churn_numeric'].sort_values(key=abs, ascending=False)\n",
        "churn_correlations = churn_correlations.drop('Churn_numeric')\n",
        "print(\"Mayores correlaciones con Churn_numeric (Ordenado por absolute value):\")\n",
        "print(churn_correlations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c0826e1"
      },
      "source": [
        "# Mostrar porcentajes en orden ascendente y como porcentajes #\n",
        "churn_correlations_percentage_asc = (churn_correlations * 100).sort_values(ascending=True)\n",
        "\n",
        "print(\"Correlaciones con Churn_Yes (en porcentajes, ascending order):\")\n",
        "print(churn_correlations_percentage_asc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Analisis dirigido a variables especificas : Duracion del contrato y gasto total con la variable Churn_numeric **"
      ],
      "metadata": {
        "id": "H_pfdEd-A8Fi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24d41a76"
      },
      "source": [
        "\n",
        "if 'correlation_matrix' in locals():\n",
        "    # correlacion entre 'customer.tenure' y 'Churn_numeric'\n",
        "    tenure_churn_correlation = correlation_matrix.loc['customer.tenure', 'Churn_numeric']\n",
        "    print(f\"La correlación entre 'customer.tenure' y 'Churn_numeric' es: {tenure_churn_correlation:.4f}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3713fb03"
      },
      "source": [
        "# **Visualizacion de los patrones  en el dataset usando graficos boxplots y scatter plots.**##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afcfb795"
      },
      "source": [
        "\n",
        "numerical_cols = df_encoded.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "\n",
        "categorical_cols_for_plotting = datos.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "\n",
        "if 'Churn_numeric' in numerical_cols:\n",
        "    numerical_cols.remove('Churn_numeric')\n",
        "\n",
        "\n",
        "if 'Churn' in categorical_cols_for_plotting:\n",
        "    categorical_cols_for_plotting.remove('Churn')\n",
        "if 'Churn_numeric' in categorical_cols_for_plotting:\n",
        "    categorical_cols_for_plotting.remove('Churn_numeric')\n",
        "\n",
        "\n",
        "print(\"Columnas numericas identificadas para plotting:\")\n",
        "print(numerical_cols)\n",
        "print(\"\\nColumnas categoricas identificadas para plotting:\")\n",
        "print(categorical_cols_for_plotting)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "70d8IbHuC-GA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5a6cd94"
      },
      "source": [
        "# Selecion de categorias  para plotting basados en el analisís de correlacion\n",
        "selected_categorical_cols = [\n",
        "    'internet.InternetService',\n",
        "    'account.Contract',\n",
        "    'account.PaymentMethod',\n",
        "    'customer.Partner',\n",
        "    'customer.Dependents',\n",
        "    'customer.SeniorCitizen',\n",
        "    'account.PaperlessBilling'\n",
        "]\n",
        "\n",
        "# Definimos la  variable objetivo\n",
        "target_variable = 'Churn_numeric'\n",
        "\n",
        "# Creamos los  boxplots correspondientes\n",
        "for col in selected_categorical_cols: # Add the loop here\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.boxplot(x=col, y=target_variable, data=datos)\n",
        "    plt.title(f'Distribución de Churn por {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Churn (0: No, 1: Yes)')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81408883"
      },
      "source": [
        "## Generacion de scatter  plots ##\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b80c3e41"
      },
      "source": [
        "# Selecion de pares de caracteristicas numericas para crear scatter plots\n",
        "\n",
        "numerical_cols = df_encoded.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "# Eliminacion de la variable R Churn_numeric de la lista, dado que es \"target\"\n",
        "if 'Churn_numeric' in numerical_cols:\n",
        "    numerical_cols.remove('Churn_numeric')\n",
        "\n",
        "# Se define los pares mas relevantes en base al analisis de correlacion y a las variables selecionadas:\n",
        "selected_pairs = [\n",
        "    ('customer.tenure', 'account.Charges.Monthly'),\n",
        "    ('customer.tenure', 'account.Charges.Total'),\n",
        "    ('account.Charges.Monthly', 'account.Charges.Total'),\n",
        "    ('customer.tenure', 'Cuentas_Diarias'),\n",
        "    ('account.Charges.Monthly', 'Cuentas_Diarias'),\n",
        "    ('account.Charges.Total', 'Cuentas_Diarias'),\n",
        "    ('customer.SeniorCitizen', 'customer.tenure')\n",
        "]\n",
        "\n",
        "# Creacion de los  scatter plots para las variables selecionadas:\n",
        "for col1, col2 in selected_pairs:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x=col1, y=col2, data=df_encoded)\n",
        "    plt.title(f'Scatter Plot of {col1} vs {col2}')\n",
        "    plt.xlabel(col1)\n",
        "    plt.ylabel(col2)\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eff8f17"
      },
      "source": [
        "## Interpretacion de los graficos, para identificar patrones potenciales y relaciones de la informacion ##\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5a86464"
      },
      "source": [
        "## Resumen:\n",
        "\n",
        "### Hallazgos Clave del Análisis de Datos\n",
        "\n",
        "* Los clientes con servicio de internet de fibra óptica, contratos mes a mes y métodos de pago de cheque electrónico parecen tener una tasa de abandono mediana más alta según los diagramas de caja.\n",
        "\n",
        "* Los diagramas de dispersión muestran relaciones distintas entre las características numéricas, como una correlación positiva entre `customer.tenure` y `account.Charges.Total`, y entre `account.Charges.Monthly` y `account.Charges.Total`.\n",
        "\n",
        "* El diagrama de dispersión de `customer.SeniorCitizen` frente a `customer.tenure` sugiere que los clientes mayores pueden tener distribuciones de permanencia ligeramente diferentes en comparación con los no mayores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *III Modelado Predictivo* #"
      ],
      "metadata": {
        "id": "vXPqpkPFXr1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separacion de Datos #"
      ],
      "metadata": {
        "id": "-3vxLtJhX5Xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZHXfSOH7X8kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_encoded.drop('Churn_numeric', axis=1)\n",
        "y = df_encoded['Churn_numeric']\n",
        "print(f\"\\nDimensiones de X (Características): {X.shape}\")\n",
        "print(f\"Dimensiones de y (Variable Objetivo): {y.shape}\")"
      ],
      "metadata": {
        "id": "nr6tv1zgYI9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dividir datos de entrenamiento y prueba #"
      ],
      "metadata": {
        "id": "S9MbYyCKYpQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "HRwN0Mh5ZBAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III.Creacion de Modelos: #\n"
      ],
      "metadata": {
        "id": "30yqx8YLZhYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicacion de Smote al conjunto de entrenamiento\""
      ],
      "metadata": {
        "id": "UxIDs8v-aOIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE # Necesitas haber instalado 'imbalanced-learn'\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "metadata": {
        "id": "dRdebrD9aTOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=42) # random_state para reproducibilidad\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nDimensiones de X_train_res después de SMOTE:\", X_train_res.shape)\n",
        "print(\"Dimensiones de y_train_res después de SMOTE:\", y_train_res.shape)\n",
        "print(\"\\nDistribución de 'Churn_numeric' en y_train_res DESPUÉS de SMOTE:\")\n",
        "print(y_train_res.value_counts())\n",
        "print(y_train_res.value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "id": "EkTcm4HdbVGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HnX8Fe9ciAGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cYnry5c9fjED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III.1 Aplicacion del primer modelo de Regresion Logistica #"
      ],
      "metadata": {
        "id": "R-X3INUab5iU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "log_reg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
        "\n",
        "print(\"Entrenando el modelo de Regresión Logística...\")\n",
        "log_reg_model.fit(X_train_res, y_train_res)\n",
        "print(\"Modelo de Regresión Logística entrenado con éxito!\\n\")"
      ],
      "metadata": {
        "id": "zMqsRRGWb_Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizar Predicciones en el conjunto de prueba (X_test)"
      ],
      "metadata": {
        "id": "V29Ckvrhk8Wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_log_reg = log_reg_model.predict(X_test) # Predicciones de clase (0 o 1)\n",
        "y_proba_log_reg = log_reg_model.predict_proba(X_test)[:, 1] # Probabilidad de la clase '1' (Churn)\n"
      ],
      "metadata": {
        "id": "Y_sAhIPdlA59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluar el Modelo"
      ],
      "metadata": {
        "id": "9sdkeRu3lLUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de Confusión: Nos muestra los aciertos y errores detalladamente.\n",
        "cm_log_reg = confusion_matrix(y_test, y_pred_log_reg)\n",
        "print(\"\\nMatriz de Confusión:\")\n",
        "print(cm_log_reg)\n",
        "\n",
        "# Visualización de la Matriz de Confusión\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_log_reg, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['No Churn (Pred)', 'Churn (Pred)'],\n",
        "            yticklabels=['No Churn (Real)', 'Churn (Real)'])\n",
        "plt.title('Matriz de Confusión - Regresión Logística')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.show()\n",
        "\n",
        "# Reporte de Clasificación: Proporciona Precision, Recall y F1-score por clase.\n",
        "print(\"\\nReporte de Clasificación:\")\n",
        "print(classification_report(y_test, y_pred_log_reg, target_names=['No Churn', 'Churn']))\n",
        "\n",
        "# AUC-ROC Score: Mide la capacidad del modelo para distinguir entre las clases.\n",
        "auc_roc_log_reg = roc_auc_score(y_test, y_proba_log_reg)\n",
        "print(f\"AUC-ROC Score: {auc_roc_log_reg:.4f}\")"
      ],
      "metadata": {
        "id": "PBjkCzQolQq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretacion de Resultados del Modelo de Regresion Lineal #\n",
        "[0,0] (arriba izquierda): Verdaderos Negativos (TN) - Clientes que no hicieron churn y el modelo predijo correctamente que no lo harían.\n",
        "\n",
        "[0,1] (arriba derecha): Falsos Positivos (FP) - Clientes que no hicieron churn, pero el modelo predijo erróneamente que sí lo harían.\n",
        "\n",
        "[1,0] (abajo izquierda): Falsos Negativos (FN) - Clientes que sí hicieron churn, pero el modelo predijo erróneamente que no lo harían.\n",
        "\n",
        "[1,1] (abajo derecha): Verdaderos Positivos (TP) - Clientes que sí hicieron churn y el modelo predijo correctamente que sí lo harían.\n"
      ],
      "metadata": {
        "id": "Q3qClJu2dy-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Informe de Clasificacion #\n"
      ],
      "metadata": {
        "id": "DxcwfLtieJPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Clase 'No Churn' (0):\n",
        "\n",
        "Precisión (0.87): De todas las predicciones de \"No Churn\", el 87% fueron correctas.\n",
        "\n",
        "Recall (0.81): El modelo identificó correctamente al 81% de todos los clientes que realmente no hicieron Churn.\n",
        "\n",
        "Clase 'Churn' (1):\n",
        "\n",
        "Precisión (0.56): De todas las predicciones de \"Churn\", solo el 56% fueron correctas. Esto significa que hay un número considerable de \"falsas alarmas\".\n",
        "\n",
        "Recall (0.65): De todos los clientes que realmente hicieron Churn, el modelo logró identificar al 65%. Esta es una métrica clave para un problema de Churn, ya que SE quiere detectar a la mayor cantidad posible de clientes en riesgo (Churn).\n",
        "\n",
        "F1-Score (0.60): Un balance entre precisión y recall para la clase Churn.\n",
        "\n",
        "AUC-ROC Score :\n",
        "\n",
        "AUC-ROC Score: 0.8228\n",
        "\n",
        "Este valor es bueno. Indica que el modelo tiene una buena capacidad general para distinguir entre los clientes que harán Churn y los que no.\n",
        "\n",
        "** Conclusión del Modelo de Regresión Logística:**\n",
        "El modelo de Regresión Logística, entrenado con los datos balanceados por SMOTE, se muestra con un rendimiento razonable:\n",
        "\n",
        "Es capaz de detectar a una proporción decente de clientes que realmente abandonarán (Recall del 65% para 'Churn').\n",
        "\n",
        "Tiene un buen poder discriminatorio general (AUC-ROC de 0.82).\n",
        "\n",
        "Analisis Critico: Un tema relevante para asegurar la confiabilidad del modelo es poder mejorar es la precisión para la clase 'Churn'. Un 56% de precisión significa que cerca de  la mitad de las veces que el modelo predice \"Churn\", en realidad se equivoca. Esto podría llevar a acciones de retención dirigidas a clientes que no estaban en riesgo real."
      ],
      "metadata": {
        "id": "o5DvYYKhH04E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III.2 Aplicacion de un segundo Modelo : Random Forest Classifier ##"
      ],
      "metadata": {
        "id": "CdxnXbURJ6lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "id": "NyYhfQl0ML_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier # Importamos el modelo Random Forest\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "qmG6kLU0P3nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_encoded.drop('Churn_numeric', axis=1)\n",
        "y = df_encoded['Churn_numeric']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Datos de entrenamiento balanceados con SMOTE listos para el modelado de Random Forest.\")\n",
        "print(f\"Dimensiones de X_train_res: {X_train_res.shape}\")\n",
        "print(f\"Dimensiones de y_train_res: {y_train_res.shape}\\n\")"
      ],
      "metadata": {
        "id": "0Qh6UsB_QMI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier # Importamos el modelo Random Forest\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "0LWFz6q2KFOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42) # 100 árboles por defecto\n",
        "\n",
        "print(\"Entrenando el modelo Random Forest con los datos balanceados...\")\n",
        "rf_model.fit(X_train_res, y_train_res)\n",
        "print(\"¡Modelo Random Forest entrenado con éxito!\\n\")"
      ],
      "metadata": {
        "id": "Kfcg0nXfK2i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Realizar Predicciones en el conjunto de prueba ---\n",
        "# Usamos el conjunto de prueba ORIGINAL para una evaluación justa.\n",
        "y_pred_rf = rf_model.predict(X_test) # Predicciones de clase (0 o 1)\n",
        "y_proba_rf = rf_model.predict_proba(X_test)[:, 1] # Probabilidad de la clase '1' (Churn)"
      ],
      "metadata": {
        "id": "wETyMXR-LIJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de Confusión\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "print(\"\\nMatriz de Confusión:\")\n",
        "print(cm_rf)"
      ],
      "metadata": {
        "id": "Y5G4DyNQLVpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de la Matriz de Confusión\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['No Churn (Pred)', 'Churn (Pred)'],\n",
        "            yticklabels=['No Churn (Real)', 'Churn (Real)'])\n",
        "plt.title('Matriz de Confusión - Random Forest')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XomW_5Y4Lg-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reporte de Clasificación\n",
        "print(\"\\nReporte de Clasificación:\")\n",
        "print(classification_report(y_test, y_pred_rf, target_names=['No Churn', 'Churn']))\n",
        "\n",
        "# AUC-ROC Score\n",
        "auc_roc_rf = roc_auc_score(y_test, y_proba_rf)\n",
        "print(f\"AUC-ROC Score: {auc_roc_rf:.4f}\")"
      ],
      "metadata": {
        "id": "Rm9fNgKfLvDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicacion de un tercer modelo :  Arbol de Decision ##\n"
      ],
      "metadata": {
        "id": "1yTqG5kYVlaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.tree import DecisionTreeClassifier # Importamos el modelo Árbol de Decisión\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "WQwScm5KVlBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = df_encoded.drop('Churn_numeric', axis=1)\n",
        "y = df_encoded['Churn_numeric']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Datos de entrenamiento balanceados con SMOTE listos para el modelado de Árbol de Decisión.\")\n",
        "print(f\"Dimensiones de X_train_res: {X_train_res.shape}\")\n",
        "print(f\"Dimensiones de y_train_res: {y_train_res.shape}\\n\")"
      ],
      "metadata": {
        "id": "Xy8GPJHaV2rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier # Importamos el modelo Árbol de Decisión\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "dt_model = DecisionTreeClassifier(random_state=42, max_depth=7) # Profundidad es 10\n",
        "\n",
        "print(\"Entrenando el modelo Árbol de Decisión con los datos balanceados...\")\n",
        "dt_model.fit(X_train_res, y_train_res)\n",
        "print(\"¡Modelo Árbol de Decisión entrenado con éxito!\\n\")\n",
        "\n",
        "\n",
        "# --- 2. Realizar Predicciones en el conjunto de prueba ---\n",
        "# Usamos el conjunto de prueba ORIGINAL para una evaluación justa.\n",
        "y_pred_dt = dt_model.predict(X_test) # Predicciones de clase (0 o 1)\n",
        "y_proba_dt = dt_model.predict_proba(X_test)[:, 1] # Probabilidad de la clase '1' (Churn)\n",
        "\n",
        "\n",
        "# --- 3. Evaluar el Modelo ---\n",
        "print(\"--- Evaluación del Modelo Árbol de Decisión ---\")\n",
        "\n",
        "# Matriz de Confusión\n",
        "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
        "print(\"\\nMatriz de Confusión:\")\n",
        "print(cm_dt)\n",
        "\n",
        "# Visualización de la Matriz de Confusión\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['No Churn (Pred)', 'Churn (Pred)'],\n",
        "            yticklabels=['No Churn (Real)', 'Churn (Real)'])\n",
        "plt.title('Matriz de Confusión - Árbol de Decisión')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.show()\n",
        "\n",
        "# Reporte de Clasificación\n",
        "print(\"\\nReporte de Clasificación:\")\n",
        "print(classification_report(y_test, y_pred_dt, target_names=['No Churn', 'Churn']))\n",
        "\n",
        "# AUC-ROC Score\n",
        "auc_roc_dt = roc_auc_score(y_test, y_proba_dt)\n",
        "print(f\"AUC-ROC Score: {auc_roc_dt:.4f}\")"
      ],
      "metadata": {
        "id": "x3CjEWIpWDaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretacion del Modelo de Árbol de Decisión (con 31 Características):\n",
        "Matriz de Confusión Implícita (a partir del Reporte):\n",
        "\n",
        "a. Verdaderos Positivos (TP): Clientes de Churn predichos correctamente. (Calculado: Recall * Support para Churn = 0.68 * 561 = ~381)\n",
        "\n",
        "b.Falsos Negativos (FN): Clientes de Churn no detectados. (Calculado: Support - TP para Churn = 561 - 381 = ~180)\n",
        "\n",
        "c.Falsos Positivos (FP): Clientes de No Churn predichos como Churn (falsas alarmas). (Calculado: TP * (1/Precision - 1) para Churn = 381 * (1/0.52 - 1) = ~352)\n",
        "\n",
        "d.Verdaderos Negativos (TN): Clientes de No Churn predichos correctamente. (Calculado: Support - FP para No Churn = 1552 - 352 = ~1200)\n",
        "\n",
        "**Métricas Clave (Clase 'Churn' - lo que es más relevante en el modelo):**\n",
        "\n",
        "a.Precision (Churn): 0.52\n",
        "\n",
        "Esto significa que de todas las veces que el modelo predijo que un cliente haría Churn, fue correcto solo el 52% de las veces. El 48% restante fueron \"falsas alarmas\" (predijo Churn, pero el cliente no lo hizo). Esto puede ser costoso si las acciones de retención son caras, de cara a lo que buca la empresa.\n",
        "\n",
        "b.Recall (Churn): 0.68\n",
        "\n",
        "De todos los clientes que realmente hicieron Churn (561 en el conjunto de prueba), el modelo logró identificar correctamente al 68%. Este es un buen Recall, indicando que el modelo es bastante efectivo para \"capturar\" a los clientes en riesgo real.\n",
        "\n",
        "c.F1-Score (Churn): 0.59\n",
        "\n",
        "Es la media armónica de precisión y recall. Un F1-Score de 0.59 estaria indicando un rendimiento moderado para la clase minoritaria.\n",
        "\n",
        "Métricas Generales:\n",
        "\n",
        "**Accuracy (Precisión Global): 0.75**\n",
        "\n",
        "El modelo clasificó correctamente al 75% de todos los clientes en el conjunto de prueba.\n",
        "\n",
        "**AUC-ROC Score: 0.8054**\n",
        "\n",
        "Este valor de 0.8054 se considera aceptable. Sugiere que el modelo tiene una buena capacidad general para distinguir entre las clases de Churn y No-Churn, aunque no es tan alta como la del Random Forest que se calculo anteriormente."
      ],
      "metadata": {
        "id": "7gOA-f_3Y6m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Modelo: Regresión Logística ---\")\n",
        "log_reg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
        "log_reg_model.fit(X_train_res, y_train_res)\n",
        "y_pred_log_reg = log_reg_model.predict(X_test)\n",
        "y_proba_log_reg = log_reg_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nMatriz de Confusión (Regresión Logística):\")\n",
        "print(confusion_matrix(y_test, y_pred_log_reg))\n",
        "print(\"\\nReporte de Clasificación (Regresión Logística):\")\n",
        "print(classification_report(y_test, y_pred_log_reg, target_names=['No Churn', 'Churn']))\n",
        "print(f\"AUC-ROC Score (Regresión Logística): {roc_auc_score(y_test, y_proba_log_reg):.4f}\\n\")\n",
        "\n",
        "\n",
        "# --- 2. Random Forest Classifier ---\n",
        "print(\"--- Modelo: Random Forest Classifier ---\")\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_res, y_train_res)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "y_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nMatriz de Confusión (Random Forest):\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"\\nReporte de Clasificación (Random Forest):\")\n",
        "print(classification_report(y_test, y_pred_rf, target_names=['No Churn', 'Churn']))\n",
        "print(f\"AUC-ROC Score (Random Forest): {roc_auc_score(y_test, y_proba_rf):.4f}\\n\")\n",
        "\n",
        "\n",
        "# --- 3. Árbol de Decisión ---\n",
        "print(\"--- Modelo: Árbol de Decisión ---\")\n",
        "dt_model = DecisionTreeClassifier(random_state=42, max_depth=7)\n",
        "dt_model.fit(X_train_res, y_train_res)\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "y_proba_dt = dt_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nMatriz de Confusión (Árbol de Decisión):\")\n",
        "print(confusion_matrix(y_test, y_pred_dt))\n",
        "print(\"\\nReporte de Clasificación (Árbol de Decisión):\")\n",
        "print(classification_report(y_test, y_pred_dt, target_names=['No Churn', 'Churn']))\n",
        "print(f\"AUC-ROC Score (Árbol de Decisión): {roc_auc_score(y_test, y_proba_dt):.4f}\\n\")\n",
        "\n",
        "print(\"--- Evaluación Comparativa de modelos ---\")"
      ],
      "metadata": {
        "id": "E0rWO6_flhvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Tabla Comparativa de Modelos **"
      ],
      "metadata": {
        "id": "NiQx_IuJuB41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultados del modelo de Regresión Logística\n",
        "log_reg_metrics = {\n",
        "    'Precision': 0.56,\n",
        "    'Recall': 0.65,\n",
        "    'F1-Score': 0.60,\n",
        "    'AUC-ROC Score': 0.8228,\n",
        "    'Accuracy Global': 0.77\n",
        "}\n",
        "\n",
        "# Resultados del modelo de Random Forest\n",
        "rf_metrics = {\n",
        "    'Precision': 0.57,\n",
        "    'Recall': 0.59,\n",
        "    'F1-Score': 0.58,\n",
        "    'AUC-ROC Score': 0.8202,\n",
        "    'Accuracy Global': 0.77\n",
        "}\n",
        "\n",
        "# Resultados del modelo de Árbol de Decisión\n",
        "dt_metrics = {\n",
        "    'Precision': 0.52,\n",
        "    'Recall': 0.68,\n",
        "    'F1-Score': 0.59,\n",
        "    'AUC-ROC Score': 0.8054,\n",
        "    'Accuracy Global': 0.75\n",
        "}\n",
        "\n",
        "# Crea un DataFrame a partir de los diccionarios\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Regresión Logística': log_reg_metrics,\n",
        "    'Random Forest Classifier': rf_metrics,\n",
        "    'Árbol de Decisión': dt_metrics\n",
        "})\n",
        "\n",
        "# Muestra el cuadro comparativo\n",
        "print(\"Cuadro Comparativo de Modelos de Clasificación:\")\n",
        "print(comparison_df)"
      ],
      "metadata": {
        "id": "QBMFJ_GzuGGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tabla Comparativa de Rendimiento de Modelos**\n",
        "Métrica / Modelo\n",
        "Regresión Logística (RL) /\tRandom Forest (RF) Classifier\t/Árbol de Decisión (AD)\n",
        "                     RL      RF      AD\n",
        "a.Churn Precision:\t0.56\t  0.57\t  0.52\n",
        "b.Churn Recall:   \t0.65\t  0.59\t  0.68\n",
        "c.Churn F1-Score :\t0.60\t  0.58\t  0.59\n",
        "d.AUC-ROC Score:  \t0.8228\t0.8202\t0.8054\n",
        "e.Accuracy Global:\t0.77\t  0.77\t  0.75\n",
        "Support (No Churn)\t1552\t1552\t1552\n",
        "Support (Churn)\t561\t561\t561\n",
        "\n",
        "Análisis y Comparación Final de los Modelos\n",
        "**1. Regresión Logística**\n",
        "Pros: Es simple, rápido, interpretable.\n",
        "Contras: A veces limitado por su naturaleza lineal.\n",
        "\n",
        "\n",
        "1.1. Churn Precision (0.56): Es la mejor entre los tres para este set de características, lo que significa menos \"falsas alarmas\" al identificar evasion.\n",
        "\n",
        "1.2 Churn Recall (0.65): Es muy bueno, capturando una gran parte de los evasores reales.\n",
        "\n",
        "1.3 Churn F1-Score (0.60): El más alto, indicando el mejor equilibrio entre precisión y recall para la clase 'Churn'.\n",
        "\n",
        "1.4 AUC-ROC (0.8228): El más alto de los tres, mostrando la mejor capacidad discriminatoria general.\n",
        "\n",
        "1.5 Accuracy (0.77): Comparte la precisión global más alta con Random Forest.\n",
        "\n",
        "**2. Random Forest Classifier**\n",
        "Pros: Potente, robusto, maneja bien datos complejos.\n",
        "Contras: Menos interpretable, puede ser más lento.\n",
        "\n",
        "\n",
        "2.1 Churn Precision (0.57): Ligeramente mejor que Regresión Logística, pero la diferencia es mínima.\n",
        "\n",
        "2.2. Churn Recall (0.59): El más bajo de los tres, lo que significa que \"pierde\" a más clientes que realmente hacen churn.\n",
        "\n",
        "2.3 Churn F1-Score (0.58): El más bajo, indicando un equilibrio menos favorable para la clase 'Churn'.\n",
        "\n",
        "2.4 AUC-ROC (0.8202): Muy cercano a Regresión Logística.\n",
        "\n",
        "2.5 Accuracy (0.77): Comparte la precisión global más alta.\n",
        "\n",
        "**3. Árbol de Decisión**\n",
        "Pros: Muy interpretable, fácil de visualizar.\n",
        "\n",
        "Contras: Muy propenso al sobreajuste si no se le controla bien (max_depth). Generalmente, un solo árbol no es tan robusto como un \"bosque\".\n",
        "\n",
        "\n",
        "3.1. Churn Precision (0.52): La más baja de los tres.\n",
        "\n",
        "3.2.Churn Recall (0.68): El más alto de los tres, lo que significa que es el mejor para capturar a la mayoría de los churners reales, aunque a costa de muchas falsas alarmas.\n",
        "\n",
        "3.2. Churn F1-Score (0.59): Intermedio.\n",
        "\n",
        "3.3. AUC-ROC (0.8054): El más bajo de los tres.\n",
        "\n",
        "3.4. Accuracy (0.75): La más baja de los tres.\n",
        "\n",
        "¿Cuál sería el mejor modelo para la variable 'Churn' (con 31 características)?\n",
        "Dado el objetivo de predecir el Churn, donde generalmente se busca un balance entre identificar a los clientes que se van (Recall) y hacerlo de manera eficiente sin demasiadas falsas alarmas (Precision), y considerando el poder discriminatorio general (AUC-ROC):\n",
        "\n",
        "El modelo de Regresión Logística se destaca como el mejor modelo en este conjunto específico de 31 características.\n",
        "\n",
        "Justificación:\n",
        "\n",
        "Mejor F1-Score para Churn (0.60): Indica que ofrece el mejor equilibrio entre la precisión y el recall para la clase 'Churn'.\n",
        "\n",
        "Mejor AUC-ROC Score (0.8228): Muestra que tiene la mejor capacidad general para distinguir entre los clientes que harán churn y los que no, lo cual es fundamental para el problema.\n",
        "\n",
        "Buena Precisión (0.56) y Recall (0.65) para Churn: Aunque su precisión no es extremadamente alta, es la mejor de los tres, y su recall es muy bueno. Esto implica que podrás identificar una buena parte de los churners reales con una tasa de falsas alarmas más manejable que con el Árbol de Decisión.\n",
        "\n",
        "Aunque el Random Forest también tiene un buen rendimiento general, su Recall para la clase Churn fue el más bajo en esta comparación (0.59), lo que significa que \"perdería\" a más clientes que realmente van a hacer churn. El Árbol de Decisión, aunque tiene un alto recall, su baja precisión lo hace menos eficiente en un escenario real donde las acciones de retención tienen un costo.\n",
        "\n"
      ],
      "metadata": {
        "id": "tuSPDnXImV_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones Finales y Recomendaciones en base al Modelo Selecionado : Regresion Lineal ##"
      ],
      "metadata": {
        "id": "UoqDuAwjnxHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Variables Claves del Modelo a considerar **"
      ],
      "metadata": {
        "id": "79bCMx0soh6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variables Claves del Modelo #\n",
        "\n",
        "*   Elemento de lista\n",
        "\n",
        "Según orden de importancia y lo que representan para Telecom:\n",
        "\n",
        "1.) account.Contract_Month-to-month (Contrato Mes a Mes):\n",
        "Es la variable más fuerte de Churn (evasion).Los clientes con contratos mensuales tienen una probabilidad significativamente más alta de abandonar la empresa.La interpretacion es que la falta de compromiso a largo plazo los hace más volátiles y propensos a cambiar.\n",
        "\n",
        "2.) internet.InternetService_Fiber optic (Servicio de Internet de Fibra Óptica):\n",
        "Esta variable tambien aumenta la probabilidad de Churn .A pesar de ser un servicio premium, los clientes con fibra óptica son más propensos a irse. Esto podría estar indicando problemas de calidad, estabilidad, soporte técnico insatisfactorio o expectativas no cumplidas para este servicio de alta velocidad.\n",
        "\n",
        "3.) account.PaymentMethod_Electronic check . Esta variable tambien incide en aumentar la probabilidad de Churn. De esta manera, los clientes que pagan con cheque electrónico tienen un mayor riesgo de abandono. Esto podría estar implicando en ctegorizar a señalar a un segmento de clientes menos bancarizados, o con procesos de pago que generan fricción o insatisfacción en general.\n",
        "\n",
        "4.) customer.tenure (Antigüedad del Cliente):\n",
        "Esta variable al presentar una correlacion negativa en el modelo, hace que disminuye la probabilidad de Churn . De esta manera, a mayor cantidad de tiempo que el cliente se mantiena en la empresa, menos probable es que se vaya.Esto implica en la practicaLa que los clientes más nuevos son más vulnerables."
      ],
      "metadata": {
        "id": "chjER-0sn9Ny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones Estrategicas y Recomendaciones Finales ##"
      ],
      "metadata": {
        "id": "nVqTYUzlrysa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I.) Incentivar Contratos a Largo Plazo:\n",
        "\n",
        "Estrategia Sugerida: Diseñar programas agresivos para migrar a clientes de contrato \"Mes a Mes\" a contratos de uno o dos años,mediante ofertas de fidelización, tales como: Descuentos atractivos, meses gratis, etc.\n",
        "\n",
        "\n",
        "II.) Mejorar la Experiencia del Cliente de Fibra Óptica:\n",
        "\n",
        "Estrategia Sugerida: Investigar y resolver los puntos de dolor específicos de los usuarios de fibra óptica, mediante el monitoreo proactivo, es decir implementar sistemas para detectar automáticamente problemas de rendimiento o interrupciones en el servicio de fibra.\n",
        "\n",
        "\n",
        "III:) Optimizar y Desincentivar el Pago con Cheque Electrónico:\n",
        "\n",
        "Estrategia Sugerida: Reducir la dependencia del cheque electrónico y facilitar métodos de pago más convenientes y estables, mediante incentivos tales como el ofrecer pequeños descuentos o bonos por migrar a pagos automáticos con tarjeta de crédito/débito o transferencia bancaria.\n",
        "\n",
        "\n",
        "IV:) Programas de Bienvenida y Fidelización Temprana (Antigüedad):\n",
        "\n",
        "Estrategia Sugerida: Reconocer que los primeros meses son críticos para la retención y por lo tanto ofrecer\n",
        "un proceso de bienvenida que asegure que el cliente entienda y utilice todos los servicios. Tambien se sugiere ofrecer ofertas post-bienvenida: Pequeños incentivos o encuestas de satisfacción después de 3 o 6 meses."
      ],
      "metadata": {
        "id": "vLppsjsYr733"
      }
    }
  ]
}