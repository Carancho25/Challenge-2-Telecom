# Challenge-2-Telecom
Continuacion de Ejercicio de Telecom
README TELECOM 2 ALURA LATAM

Predicci√≥n de Abandono de Clientes (Churn) en Telecomunicaciones
üìù Descripci√≥n del Proyecto
Este proyecto se centra en construir y evaluar modelos de Machine Learning para predecir el abandono de clientes (Churn) en una empresa de telecomunicaciones. El objetivo principal es identificar a los clientes con alta probabilidad de irse ( evasi√≥n), comprender los factores que impulsan su decisi√≥n y proponer estrategias de retenci√≥n basadas en estos hallazgos.
üéØ Objetivo
El objetivo principal es:
‚Ä¢	Desarrollar un modelo predictivo que pueda identificar a los clientes en riesgo de Churn con alta precisi√≥n y recall.
‚Ä¢	Analizar las variables m√°s influyentes en el Churn para obtener insights accionables.
‚Ä¢	Proponer estrategias de negocio basadas en estos insights para mejorar la retenci√≥n de clientes.
üìä Dataset
El an√°lisis se realiza sobre el archivo datos_limpios.csv, el cual contiene informaci√≥n de clientes de una compa√±√≠a de telecomunicaciones, incluyendo datos demogr√°ficos, servicios contratados, informaci√≥n de facturaci√≥n y, crucialmente, si el cliente ha abandonado la empresa (Churn_numeric).
üõ†Ô∏è Metodolog√≠a y Pasos Realizados
El proyecto sigue un flujo de trabajo est√°ndar de Machine Learning:
1.	Carga y Limpieza de Datos Inicial:
o	Carga del dataset datos_limpios.csv.
o	Manejo de valores perdidos (NaN) en la columna account.Charges.Total.
o	Eliminaci√≥n de la columna customerID (identificador √∫nico no relevante para el modelado).
o	Filtrado de registros con Churn_numeric igual a -1.
2.	Preprocesamiento de Datos:
o	Codificaci√≥n One-Hot: Conversi√≥n de variables categ√≥ricas (como tipo de contrato, servicio de internet, m√©todo de pago, etc.) a un formato num√©rico utilizando pd.get_dummies (resultando en 31 caracter√≠sticas finales).
3.	Divisi√≥n de Datos:
o	El dataset se dividi√≥ en conjuntos de entrenamiento (70%) y prueba (30%) utilizando train_test_split, asegurando la estratificaci√≥n por la variable Churn_numeric para mantener la proporci√≥n de clases.
4.	Manejo de Desbalance de Clases (SMOTE):
o	Debido al desbalance inherente en los datos de Churn (menos clientes que abandonan que los que se quedan), se aplic√≥ SMOTE (Synthetic Minority Over-sampling Technique) al conjunto de entrenamiento. Esto cre√≥ muestras sint√©ticas de la clase minoritaria (Churn) para equilibrar el dataset y mejorar el aprendizaje del modelo.
5.	Entrenamiento y Evaluaci√≥n de Modelos:
o	Se entrenaron y evaluaron tres modelos de clasificaci√≥n populares:
ÔÇß	Regresi√≥n Log√≠stica: Un modelo lineal que predice la probabilidad de Churn.
ÔÇß	Random Forest Classifier: Un modelo de conjunto robusto que combina m√∫ltiples √°rboles de decisi√≥n.
ÔÇß	√Årbol de Decisi√≥n: Un modelo interpretable que crea reglas de decisi√≥n.
o	Cada modelo fue evaluado utilizando m√©tricas clave para problemas de desbalance de clases: Matriz de Confusi√≥n, Reporte de Clasificaci√≥n (Precision, Recall, F1-Score para la clase 'Churn') y AUC-ROC Score. Todos los modelos se entrenaron con el conjunto de datos balanceado por SMOTE y se evaluaron en el conjunto de prueba original.
6.	Selecci√≥n del Modelo:
o	Se compar√≥ el rendimiento de los tres modelos utilizando las m√©tricas mencionadas, prestando especial atenci√≥n a la precisi√≥n, recall, F1-Score para la clase 'Churn' y el AUC-ROC.
o	El Modelo de Regresi√≥n Log√≠stica fue seleccionado como el mejor en esta configuraci√≥n (31 caracter√≠sticas), ofreciendo el mejor equilibrio de m√©tricas para la predicci√≥n de Churn.
7.	An√°lisis de Importancia de Variables (Regresi√≥n Log√≠stica):
o	Se extrajeron y analizaron los coeficientes del modelo de Regresi√≥n Log√≠stica para identificar las caracter√≠sticas con mayor impacto en la probabilidad de Churn, y si su impacto era positivo (aumenta Churn) o negativo (disminuye Churn).
8.	Propuesta de Estrategias de Retenci√≥n:
o	Se formularon estrategias de negocio accionables basadas en los insights obtenidos del an√°lisis de las variables m√°s relevantes.
üìà Resultados Clave y Modelo Seleccionado
Despu√©s de una evaluaci√≥n comparativa con 31 caracter√≠sticas consistentes, el modelo de Regresi√≥n Log√≠stica demostr√≥ ser el m√°s efectivo.
M√©tricas del Modelo de Regresi√≥n Log√≠stica (para la clase 'Churn'):
‚Ä¢	Precision: 0.56
‚Ä¢	Recall: 0.65
‚Ä¢	F1-Score: 0.60
‚Ä¢	AUC-ROC: 0.8228
‚Ä¢	Accuracy Global: 0.77
Variables M√°s Relevantes Identificadas:
Las variables que m√°s influyen en la probabilidad de Churn (en orden de impacto) son:
‚Ä¢	account.Contract_Month-to-month: Principal impulsor de Churn.
‚Ä¢	internet.InternetService_Fiber optic: Los usuarios de fibra √≥ptica tienen mayor Churn.
‚Ä¢	account.PaymentMethod_Electronic check: Este m√©todo de pago se asocia con mayor riesgo.
‚Ä¢	customer.tenure: A mayor antig√ºedad, menor probabilidad de Churn (factor protector).

o	üí° Estrategias de Retenci√≥n Propuestas
Basadas en el an√°lisis del modelo de Regresi√≥n Log√≠stica, se proponen las siguientes estrategias:
1.	Incentivar Contratos a Largo Plazo: Dise√±ar ofertas atractivas para que los clientes mensuales migren a planes anuales o bienales.
2.	Mejorar la Experiencia de Fibra √ìptica: Investigar problemas de calidad o soporte para usuarios de fibra √≥ptica.
3.	Optimizar M√©todos de Pago: Fomentar el uso de m√©todos de pago autom√°ticos (tarjeta, transferencia) sobre cheques electr√≥nicos.
4.	Programas de Bienvenida y Fidelizaci√≥n Temprana: Ofrecer atenci√≥n y beneficios especiales a clientes nuevos.

üöÄ C√≥mo se  Ejecuto el Proyecto:
Para replicar este an√°lisis en Google Colab:
1.	Abre el ‚Äúarchivo‚Äù .ipynb en Google Colab.
2.	Se sube el archivo datos_limpios.csv al entorno de Colab (hazer clic en el icono de carpeta en el panel izquierdo, luego en el icono de "subir archivo").
3.	Ejecutar la celda de instalaci√≥n de librer√≠as al inicio:
Python
!pip install imbalanced-learn
(Es crucial ejecutar esta celda primero, especialmente si el entorno de Colab se reinicia, ya que las librer√≠as instaladas no persisten).
4.	Ejecutar las celdas de c√≥digo secuencialmente de arriba a abajo.
üíª Tecnolog√≠as Utilizadas
‚Ä¢	Python 3
‚Ä¢	Pandas: Para manipulaci√≥n y an√°lisis de datos.
‚Ä¢	Numpy: Para operaciones num√©ricas.
‚Ä¢	Scikit-learn: Para construcci√≥n y evaluaci√≥n de modelos de Machine Learning (Regresi√≥n Log√≠stica, Random Forest, √Årbol de Decisi√≥n).
‚Ä¢	Imbalanced-learn (imblearn): Para manejar el desbalance de clases con SMOTE.
‚Ä¢	Matplotlib: Para visualizaci√≥n de datos.
‚Ä¢	Seaborn: Para visualizaci√≥n de datos.

